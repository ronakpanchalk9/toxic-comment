# Toxic Comment Classifier
In this project, I've build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. Using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.
# Libraries Used:
* Python
* Pandas
* Numpy
* Sklearn
* Tensorflow
* Keras
